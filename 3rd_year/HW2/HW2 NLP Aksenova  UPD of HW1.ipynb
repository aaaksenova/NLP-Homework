{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  HW1 NLP Anna Aksenova"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом ноутбуке мы будем проводить анализ тональности на текстах из отзывов на IMDB о Гарри Поттере."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pprint import pprint\n",
    "import time\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as ec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Берем ссылку на IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://www.imdb.com/title/tt0241527/reviews?spoiler=hide&sort=helpfulnessScore&dir=desc&ratingFilter=0 '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = requests.get(link)\n",
    "html = result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# эта функция открывает IMDB и кликает на кнопку, открывающую продолжение комментариев\n",
    "def get_comments(url_add, maxclicks):\n",
    "    \n",
    "    progress_bar = tqdm(total = maxclicks)\n",
    "\n",
    "    source_code = requests.get(url_add)\n",
    "    plain_text = source_code.text\n",
    "    soup = BeautifulSoup(plain_text, 'html.parser')\n",
    "\n",
    "\n",
    "    driver = webdriver.Chrome('/Users/annaaksenova/Desktop/chromedriver')\n",
    "    wait = WebDriverWait(driver, 100)\n",
    "\n",
    "    driver.get(url_add)\n",
    "    \n",
    "    clicks = 0\n",
    "    while True:\n",
    "        clicks += 1\n",
    "        if clicks <= maxclicks:\n",
    "            more_button = wait.until(ec.visibility_of_element_located((By.CLASS_NAME, \"ipl-load-more__button\"))).click()\n",
    "\n",
    "\n",
    "        else:\n",
    "            break\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "    time.sleep(25)\n",
    "    source_code = driver.page_source\n",
    "\n",
    "    plain_text = source_code\n",
    "    soup = BeautifulSoup(plain_text, 'html.parser')\n",
    "\n",
    "    database = []\n",
    "    pageno = 1\n",
    "    rating_list = []\n",
    "    review_list = []\n",
    "\n",
    "    for r in soup.find_all('div', {'class': 'lister-item-content'}):\n",
    "\n",
    "        if \"ipl-ratings-bar\" in str(r):\n",
    "\n",
    "            for rating in r.find_all('span', {'class': 'rating-other-user-rating'}):\n",
    "                rating = str(rating.text).strip()\n",
    "                if rating == '':\n",
    "                    rating = 'NaN'\n",
    "                rating_list.append(rating)\n",
    "\n",
    "        for review in r.find_all('div', {'class': 'text'}):\n",
    "            review = str(review.text)\n",
    "            if review == '':\n",
    "                review = 'NaN'\n",
    "                review_list.append(review)\n",
    "            else:\n",
    "                review_list.append(review)\n",
    "        progress_bar.close()\n",
    "    return rating_list, review_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0e205f14a44508a3220108a7a34971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rating_list, review_list = get_comments(link, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем комментарии, в которых проставлены оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_rate = [(int(com[0].split('/')[0]), com[1]) for com in zip(rating_list, review_list) if not com[0].isalpha()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем считать все оценки от 8 и выше положительными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = [com for com in com_rate if com[0]>=8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все оценки от 3 и ниже будем считать отрицательными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = [com for com in com_rate if com[0]<=3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, сколько у нас вообще отзывов каждого типа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сбалансируем выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_val = [(1, i) for i in positive[len(negative) - 10:len(negative)]]\n",
    "negative_val = [(0, i) for i in negative[len(negative) - 10:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# эта функция собирает частотный словарь в 100 слов по дефолту\n",
    "def collect_freqlist(reviews, max_len=100):\n",
    "    \n",
    "    freqlist = Counter()\n",
    "    for text in reviews:\n",
    "        for word in nltk.word_tokenize(text[1].lower()):\n",
    "            if word.isalpha():\n",
    "                word = lemmatizer.lemmatize(word)\n",
    "                freqlist[word] += 1\n",
    "    return dict(freqlist.most_common(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_list = collect_freqlist(positive[:len(negative) - 10])\n",
    "negative_list = collect_freqlist(negative[:len(negative) - 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_list = set(positive_list.keys())\n",
    "negative_list = set(negative_list.keys())\n",
    "common = positive_list.intersection(negative_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_list.symmetric_difference_update(common)\n",
    "negative_list.symmetric_difference_update(common)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавляем биграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый тип биграммы – не + прилагательное. Это поможет нам выделить негативные отзывы, тк там встречаются прилагательные с положительной оценкой под отрицанием, а униграммы это не выделяют."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_neglist(reviews, max_len=20):\n",
    "    \n",
    "    freqlist = Counter()\n",
    "    for text in reviews:\n",
    "        no = ''\n",
    "        doc = nlp(text[1].lower())\n",
    "        for sent in doc.sents:\n",
    "            for t in sent:\n",
    "                if no == '':\n",
    "                    if t.lemma_ == \"not\":\n",
    "                        no = \"not\"\n",
    "                else:\n",
    "                    if t.pos_ == 'ADJ':\n",
    "                        freqlist[no + ' ' + lemmatizer.lemmatize(t.text)] += 1 \n",
    "                    no = ''\n",
    "\n",
    "\n",
    "    return dict(freqlist.most_common(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_list.difference_update(common)\n",
    "negative_list.difference_update(common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_neglist = collect_neglist(positive[:len(negative) - 10])\n",
    "negative_neglist = collect_neglist(negative[:len(negative) - 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_neglist = set(positive_neglist.keys())\n",
    "negative_neglist = set(negative_neglist.keys())\n",
    "common_neg = positive_neglist.intersection(negative_neglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_neglist.difference_update(common_neg)\n",
    "negative_neglist.difference_update(common_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второй тип биграммы – прил + сущ. Так мы поймем, за что хвалят и за что ругают фильм. Например beloved character VS bad acting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_adjlist(reviews, max_len=20):\n",
    "    \n",
    "    freqlist = Counter()\n",
    "    for text in reviews:\n",
    "        adj = ''\n",
    "        doc = nlp(text[1].lower())\n",
    "        for sent in doc.sents:\n",
    "            for t in sent:\n",
    "                if adj == '':\n",
    "                    if t.pos_ == \"ADJ\":\n",
    "                        adj = lemmatizer.lemmatize(t.text)\n",
    "                else:\n",
    "                    if t.pos_ == 'NOUN':\n",
    "                        freqlist[adj + ' ' + lemmatizer.lemmatize(t.text)] += 1 \n",
    "                        adj = ''\n",
    "                    elif t.pos_ != 'ADJ':\n",
    "                        adj = ''  \n",
    "                    else:\n",
    "                        adj = t.text\n",
    "    return dict(freqlist.most_common(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_adjlist = collect_adjlist(positive[:len(negative) - 10])\n",
    "negative_adjlist = collect_adjlist(negative[:len(negative) - 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_adjlist = set(positive_adjlist.keys())\n",
    "negative_adjlist = set(negative_adjlist.keys())\n",
    "common_adj = positive_adjlist.intersection(negative_adjlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_adjlist.difference_update(common_adj)\n",
    "negative_adjlist.difference_update(common_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Третий тип групп – глагол + наречие. Таким образом мы найдем группы типа \"played terribly\" или \"fitted perfectly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_advlist(reviews, max_len=20):\n",
    "    \n",
    "    freqlist = Counter()\n",
    "    for text in reviews:\n",
    "        adv = ''\n",
    "        doc = nlp(text[1].lower())\n",
    "        for sent in doc.sents:\n",
    "            for t in sent:\n",
    "                if adv == '':\n",
    "                    if t.pos_ == \"VERB\":\n",
    "                        adv = lemmatizer.lemmatize(t.text)\n",
    "                else:\n",
    "                    if t.pos_ == 'ADV':\n",
    "                        freqlist[adv + ' ' + lemmatizer.lemmatize(t.text)] += 1 \n",
    "                        adv = ''\n",
    "                    elif t.pos_ != 'VERB':\n",
    "                        adv = ''  \n",
    "                    else:\n",
    "                        adv = t.text\n",
    "    return dict(freqlist.most_common(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_advlist = collect_advlist(positive[:len(negative) - 10])\n",
    "negative_advlist = collect_advlist(negative[:len(negative) - 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_advlist = set(positive_advlist.keys())\n",
    "negative_advlist = set(negative_advlist.keys())\n",
    "common_adv = positive_advlist.intersection(negative_advlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_advlist.difference_update(common_adv)\n",
    "negative_advlist.difference_update(common_adv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберем множества положительного и отрицательного словаря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pos = positive_list.union(positive_adjlist, positive_neglist, positive_advlist)\n",
    "all_neg = negative_list.union(negative_adjlist, negative_neglist, negative_advlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определение типа отзыва по словам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_detect(text):\n",
    "    \n",
    "    words = [lemmatizer.lemmatize(word) for word in nltk.word_tokenize(text[1][1].lower())]\n",
    "    words = ' '.join(words)\n",
    "    words = words.replace(\"\"\"n't\"\"\", 'not')\n",
    "    pos_rank = 0\n",
    "    neg_rank = 0\n",
    "    for pos, neg in zip(all_pos, all_neg):\n",
    "        if pos in words:\n",
    "            pos_rank += 1\n",
    "        if neg in words:\n",
    "            neg_rank += 1\n",
    "    if pos_rank >= neg_rank:\n",
    "        check = 1\n",
    "    else:\n",
    "        check = 0\n",
    "    return check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "for text in positive_val + negative_val:\n",
    "    answers.append(rate_detect(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля верных ответов: 0.6\n"
     ]
    }
   ],
   "source": [
    "print(\"Доля верных ответов:\", accuracy_score(answers, [1 if i < 10 else 0 for i in range(20)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На самом деле ничего не улучшилось. Это произошло потому что очень маленькие тренировочные и тестовые выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
